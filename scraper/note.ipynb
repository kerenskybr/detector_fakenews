{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer as count_vect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import nltk\n",
    "\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo_noticia</th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indústria brasileira reage com melhora do comé...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2013/12/03/ec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A bancarrota de Detroit deixa no ar as pensões...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2013/12/03/ec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIB no Brasil cai 0,5% na leitura trimestral, ...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2013/12/03/ec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O órgão supervisor europeu questiona o trabalh...</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2013/12/02/ec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vega Sicilia, a ilusão da escassez</td>\n",
       "      <td>https://brasil.elpais.com/brasil/2013/11/29/ec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      titulo_noticia  \\\n",
       "0  Indústria brasileira reage com melhora do comé...   \n",
       "1  A bancarrota de Detroit deixa no ar as pensões...   \n",
       "2  PIB no Brasil cai 0,5% na leitura trimestral, ...   \n",
       "3  O órgão supervisor europeu questiona o trabalh...   \n",
       "4                Vega Sicilia, a ilusão da escassez    \n",
       "\n",
       "                                                 url  label  \n",
       "0  https://brasil.elpais.com/brasil/2013/12/03/ec...      0  \n",
       "1  https://brasil.elpais.com/brasil/2013/12/03/ec...      0  \n",
       "2  https://brasil.elpais.com/brasil/2013/12/03/ec...      0  \n",
       "3  https://brasil.elpais.com/brasil/2013/12/02/ec...      0  \n",
       "4  https://brasil.elpais.com/brasil/2013/11/29/ec...      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsa = pd.read_csv(r'/home/roger/Documents/detector_fakenews/scraper/noticia_falsa/csv/boatos_org.csv')\n",
    "verdadeira = pd.read_csv(r'/home/roger/Documents/detector_fakenews/scraper/noticia_verdadeira/csv/elpais.csv')\n",
    "\n",
    "\n",
    "falsa = falsa.drop(columns=['quant', 'tema'])\n",
    "\n",
    "#dropando itens para que ambos datasets tenham mesmo tamanho\n",
    "#ate arranjar mais dados para o outro\n",
    "verdadeira = verdadeira.drop(verdadeira.index[900:])\n",
    "\n",
    "verdadeira = verdadeira.drop(columns=['quant'])\n",
    "\n",
    "#Atribuindo a classe classificadora\n",
    "# 1 para falso, 0 para verdadeiro\n",
    "\n",
    "falsa['label'] = 1\n",
    "verdadeira['label'] = 0\n",
    "\n",
    "verdadeira.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo_noticia</th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neto de Chico Buarque fez versão de Águas de M...</td>\n",
       "      <td>www.boatos.org/entretenimento/neto-chico-buarq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Correios, em 2018, contrata em site “Correios ...</td>\n",
       "      <td>www.boatos.org/tecnologia/correios-2018-contra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caseiro do sítio de Atibaia diz que Lula tem c...</td>\n",
       "      <td>www.boatos.org/politica/caseiro-sitio-atibaia-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vídeo mostra rato tomando banho com sabonete e...</td>\n",
       "      <td>www.boatos.org/mundo/video-rato-tomando-banho....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lutadora de vale tudo morre após enfrentar adv...</td>\n",
       "      <td>www.boatos.org/esporte/lutadora-morre-adversar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      titulo_noticia  \\\n",
       "0  Neto de Chico Buarque fez versão de Águas de M...   \n",
       "1  Correios, em 2018, contrata em site “Correios ...   \n",
       "2  Caseiro do sítio de Atibaia diz que Lula tem c...   \n",
       "3  Vídeo mostra rato tomando banho com sabonete e...   \n",
       "4  Lutadora de vale tudo morre após enfrentar adv...   \n",
       "\n",
       "                                                 url  label  \n",
       "0  www.boatos.org/entretenimento/neto-chico-buarq...      1  \n",
       "1  www.boatos.org/tecnologia/correios-2018-contra...      1  \n",
       "2  www.boatos.org/politica/caseiro-sitio-atibaia-...      1  \n",
       "3  www.boatos.org/mundo/video-rato-tomando-banho....      1  \n",
       "4  www.boatos.org/esporte/lutadora-morre-adversar...      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.concat([verdadeira,falsa])\n",
    "\n",
    "#print(dados)\n",
    "\n",
    "#Label encoder transforma valores categoricos em numericos\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(dados.label.values)\n",
    "x = dados.titulo_noticia.values\n",
    "\n",
    "#print('printando x',x)\n",
    "\n",
    "#Stratify = retorna mesma proporção\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=43, test_size=.33, stratify=y)\n",
    "\n",
    "#print(collections.Counter(y_train))\n",
    "\n",
    "#arq3 = \"y_test.sav\"\n",
    "#joblib.dump(y_test, arq3)\n",
    "\n",
    "\n",
    "\n",
    "collections.Counter(y_test)\n",
    "\n",
    "#print(x_train.shape)\n",
    "#print(x_test.shape)\n",
    "\n",
    "#TF-IDF\n",
    "\n",
    "#Baixando o 'bag of words'\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#Vetorizando palavras para numeros\n",
    "\n",
    "pt_stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 3, strip_accents = 'unicode', max_features = 3000,\n",
    "                        analyzer = 'word', token_pattern = '\\w{1,}',\n",
    "                        ngram_range = (1,3), sublinear_tf = 1, stop_words = pt_stopwords)\n",
    "\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia do modelo LR:  0.8873949579831932\n",
      "[0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0\n",
      " 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1\n",
      " 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0\n",
      " 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0\n",
      " 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1\n",
      " 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1\n",
      " 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "#Testando com Regressao Logistica\n",
    "#################################\n",
    "\n",
    "\n",
    "#testando = tfidf.transform(texto_teste)\n",
    "\n",
    "#print('TESTANDO', testando)\n",
    "\n",
    "classificador = LogisticRegression()\n",
    "classificador.fit(x_train_tfidf, y_train)\n",
    "\n",
    "classificador.predict_proba(x_test_tfidf)\n",
    "\n",
    "print('Acuracia do modelo LR: '\n",
    "\t,classificador.score(x_test_tfidf, y_test))\n",
    "\n",
    "y_pred=classificador.predict(x_test_tfidf)\n",
    "\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#cnf_matrix = metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_teste = ['Assalto programado para quem tem SKY, NET e GVT']\n",
    "#texto_teste = ['Exames de Bolsonaro apontam pneumonia, diz boletim médico']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 403)\t1.0\n",
      "y [0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testando = tfidf.transform(texto_teste)\n",
    "\n",
    "print(testando)\n",
    "\n",
    "\n",
    "y_pred = classificador.predict(testando)\n",
    "\n",
    "print('y', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roger/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:181: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(texto_teste, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59184222, 0.40815778]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.predict_proba(testando)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
